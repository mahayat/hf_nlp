{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250bd0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://huggingface.co/learn/nlp-course/chapter3/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3de35204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahayat/opt/anaconda3/envs/myhf/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c7944e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae1d8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Model Parameters: 109.48 M\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Model Parameters: {round(model.num_parameters()/1e6, 2)} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec91ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"This course is amazing!\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b779c07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b3a60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
       "          2607,  2026,  2878,  2166,  1012,   102],\n",
       "        [  101,  2023,  2607,  2003,  6429,   999,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e466ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"labels\"] = torch.tensor([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af030388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
       "          2607,  2026,  2878,  2166,  1012,   102],\n",
       "        [  101,  2023,  2607,  2003,  6429,   999,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([1, 1])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb4622d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahayat/opt/anaconda3/envs/myhf/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "169bdb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.5666, grad_fn=<NllLossBackward0>), logits=tensor([[ 0.0625,  0.3754],\n",
       "        [-0.0055,  0.2254]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(**batch)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d90b0e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4224, 0.5776],\n",
       "        [0.4425, 0.5575]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.logits.softmax(dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4620c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5666, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model(**batch).loss\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbebaed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54c1abd",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d45f9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d576ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = raw_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7cb960c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3c64e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc026c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences_1 = tokenizer(raw_datasets[\"train\"][\"sentence1\"])\n",
    "tokenized_sentences_2 = tokenizer(raw_datasets[\"train\"][\"sentence2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa49f489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3668"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw_datasets\n",
    "# - train\n",
    "#     - 'sentence1'\n",
    "#     - 'sentence2'\n",
    "#     - 'label'\n",
    "#     - 'idx'\n",
    "\n",
    "len(raw_datasets[\"train\"][\"sentence1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36926ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2026, 2171, 2003, 9108, 8273, 2140, 10974, 4017, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"My name is Md Abul Hayat\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86f04f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2026, 2171, 2003, 102, 9108, 8273, 2140, 10974, 4017, 102], 'token_type_ids': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"My name is\", \"Md Abul Hayat\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d63db2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenizer(\n",
    "    raw_datasets[\"train\"][\"sentence1\"],\n",
    "    raw_datasets[\"train\"][\"sentence2\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "adc142cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "08c252bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3668"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "69fc4362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b10f0245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████| 408/408 [00:00<00:00, 6153.04 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b3b4f27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_datasets['train'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a78a37a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1eed3046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "56b21dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bf0879db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[101,\n",
       "  2572,\n",
       "  3217,\n",
       "  5831,\n",
       "  5496,\n",
       "  2010,\n",
       "  2567,\n",
       "  1010,\n",
       "  3183,\n",
       "  2002,\n",
       "  2170,\n",
       "  1000,\n",
       "  1996,\n",
       "  7409,\n",
       "  1000,\n",
       "  1010,\n",
       "  1997,\n",
       "  9969,\n",
       "  4487,\n",
       "  23809,\n",
       "  3436,\n",
       "  2010,\n",
       "  3350,\n",
       "  1012,\n",
       "  102,\n",
       "  7727,\n",
       "  2000,\n",
       "  2032,\n",
       "  2004,\n",
       "  2069,\n",
       "  1000,\n",
       "  1996,\n",
       "  7409,\n",
       "  1000,\n",
       "  1010,\n",
       "  2572,\n",
       "  3217,\n",
       "  5831,\n",
       "  5496,\n",
       "  2010,\n",
       "  2567,\n",
       "  1997,\n",
       "  9969,\n",
       "  4487,\n",
       "  23809,\n",
       "  3436,\n",
       "  2010,\n",
       "  3350,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  9805,\n",
       "  3540,\n",
       "  11514,\n",
       "  2050,\n",
       "  3079,\n",
       "  11282,\n",
       "  2243,\n",
       "  1005,\n",
       "  1055,\n",
       "  2077,\n",
       "  4855,\n",
       "  1996,\n",
       "  4677,\n",
       "  2000,\n",
       "  3647,\n",
       "  4576,\n",
       "  1999,\n",
       "  2687,\n",
       "  2005,\n",
       "  1002,\n",
       "  1016,\n",
       "  1012,\n",
       "  1019,\n",
       "  4551,\n",
       "  1012,\n",
       "  102,\n",
       "  9805,\n",
       "  3540,\n",
       "  11514,\n",
       "  2050,\n",
       "  4149,\n",
       "  11282,\n",
       "  2243,\n",
       "  1005,\n",
       "  1055,\n",
       "  1999,\n",
       "  2786,\n",
       "  2005,\n",
       "  1002,\n",
       "  6353,\n",
       "  2509,\n",
       "  2454,\n",
       "  1998,\n",
       "  2853,\n",
       "  2009,\n",
       "  2000,\n",
       "  3647,\n",
       "  4576,\n",
       "  2005,\n",
       "  1002,\n",
       "  1015,\n",
       "  1012,\n",
       "  1022,\n",
       "  4551,\n",
       "  1999,\n",
       "  2687,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2027,\n",
       "  2018,\n",
       "  2405,\n",
       "  2019,\n",
       "  15147,\n",
       "  2006,\n",
       "  1996,\n",
       "  4274,\n",
       "  2006,\n",
       "  2238,\n",
       "  2184,\n",
       "  1010,\n",
       "  5378,\n",
       "  1996,\n",
       "  6636,\n",
       "  2005,\n",
       "  5096,\n",
       "  1010,\n",
       "  2002,\n",
       "  2794,\n",
       "  1012,\n",
       "  102,\n",
       "  2006,\n",
       "  2238,\n",
       "  2184,\n",
       "  1010,\n",
       "  1996,\n",
       "  2911,\n",
       "  1005,\n",
       "  1055,\n",
       "  5608,\n",
       "  2018,\n",
       "  2405,\n",
       "  2019,\n",
       "  15147,\n",
       "  2006,\n",
       "  1996,\n",
       "  4274,\n",
       "  1010,\n",
       "  5378,\n",
       "  1996,\n",
       "  14792,\n",
       "  2005,\n",
       "  5096,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2105,\n",
       "  6021,\n",
       "  19481,\n",
       "  13938,\n",
       "  2102,\n",
       "  1010,\n",
       "  21628,\n",
       "  6661,\n",
       "  2020,\n",
       "  2039,\n",
       "  2539,\n",
       "  16653,\n",
       "  1010,\n",
       "  2030,\n",
       "  1018,\n",
       "  1012,\n",
       "  1018,\n",
       "  1003,\n",
       "  1010,\n",
       "  2012,\n",
       "  1037,\n",
       "  1002,\n",
       "  1018,\n",
       "  1012,\n",
       "  5179,\n",
       "  1010,\n",
       "  2383,\n",
       "  3041,\n",
       "  2275,\n",
       "  1037,\n",
       "  2501,\n",
       "  2152,\n",
       "  1997,\n",
       "  1037,\n",
       "  1002,\n",
       "  1018,\n",
       "  1012,\n",
       "  5401,\n",
       "  1012,\n",
       "  102,\n",
       "  21628,\n",
       "  6661,\n",
       "  5598,\n",
       "  2322,\n",
       "  16653,\n",
       "  1010,\n",
       "  2030,\n",
       "  1018,\n",
       "  1012,\n",
       "  1020,\n",
       "  1003,\n",
       "  1010,\n",
       "  2000,\n",
       "  2275,\n",
       "  1037,\n",
       "  2501,\n",
       "  5494,\n",
       "  2152,\n",
       "  2012,\n",
       "  1037,\n",
       "  1002,\n",
       "  1018,\n",
       "  1012,\n",
       "  5401,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  4518,\n",
       "  3123,\n",
       "  1002,\n",
       "  1016,\n",
       "  1012,\n",
       "  2340,\n",
       "  1010,\n",
       "  2030,\n",
       "  2055,\n",
       "  2340,\n",
       "  3867,\n",
       "  1010,\n",
       "  2000,\n",
       "  2485,\n",
       "  5958,\n",
       "  2012,\n",
       "  1002,\n",
       "  2538,\n",
       "  1012,\n",
       "  4868,\n",
       "  2006,\n",
       "  1996,\n",
       "  2047,\n",
       "  2259,\n",
       "  4518,\n",
       "  3863,\n",
       "  1012,\n",
       "  102,\n",
       "  18720,\n",
       "  1004,\n",
       "  1041,\n",
       "  13058,\n",
       "  1012,\n",
       "  6661,\n",
       "  5598,\n",
       "  1002,\n",
       "  1015,\n",
       "  1012,\n",
       "  6191,\n",
       "  2030,\n",
       "  1022,\n",
       "  3867,\n",
       "  2000,\n",
       "  1002,\n",
       "  2538,\n",
       "  1012,\n",
       "  6021,\n",
       "  2006,\n",
       "  1996,\n",
       "  2047,\n",
       "  2259,\n",
       "  4518,\n",
       "  3863,\n",
       "  2006,\n",
       "  5958,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  6599,\n",
       "  1999,\n",
       "  1996,\n",
       "  2034,\n",
       "  4284,\n",
       "  1997,\n",
       "  1996,\n",
       "  2095,\n",
       "  3333,\n",
       "  2321,\n",
       "  3867,\n",
       "  2013,\n",
       "  1996,\n",
       "  2168,\n",
       "  2558,\n",
       "  1037,\n",
       "  2095,\n",
       "  3041,\n",
       "  1012,\n",
       "  102,\n",
       "  2007,\n",
       "  1996,\n",
       "  9446,\n",
       "  5689,\n",
       "  2058,\n",
       "  5954,\n",
       "  1005,\n",
       "  1055,\n",
       "  2194,\n",
       "  1010,\n",
       "  6599,\n",
       "  1996,\n",
       "  2034,\n",
       "  4284,\n",
       "  1997,\n",
       "  1996,\n",
       "  2095,\n",
       "  3333,\n",
       "  2321,\n",
       "  3867,\n",
       "  2013,\n",
       "  1996,\n",
       "  2168,\n",
       "  2558,\n",
       "  1037,\n",
       "  2095,\n",
       "  3041,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  17235,\n",
       "  2850,\n",
       "  4160,\n",
       "  2018,\n",
       "  1037,\n",
       "  4882,\n",
       "  5114,\n",
       "  1997,\n",
       "  2459,\n",
       "  1012,\n",
       "  2676,\n",
       "  1010,\n",
       "  2030,\n",
       "  1015,\n",
       "  1012,\n",
       "  1016,\n",
       "  3867,\n",
       "  1010,\n",
       "  5494,\n",
       "  2012,\n",
       "  1015,\n",
       "  1010,\n",
       "  19611,\n",
       "  1012,\n",
       "  2321,\n",
       "  2006,\n",
       "  5958,\n",
       "  1012,\n",
       "  102,\n",
       "  1996,\n",
       "  6627,\n",
       "  1011,\n",
       "  17958,\n",
       "  17235,\n",
       "  2850,\n",
       "  4160,\n",
       "  12490,\n",
       "  1012,\n",
       "  11814,\n",
       "  2594,\n",
       "  24356,\n",
       "  2382,\n",
       "  1012,\n",
       "  4805,\n",
       "  2685,\n",
       "  1010,\n",
       "  2030,\n",
       "  1016,\n",
       "  1012,\n",
       "  5840,\n",
       "  3867,\n",
       "  1010,\n",
       "  2000,\n",
       "  1015,\n",
       "  1010,\n",
       "  19611,\n",
       "  1012,\n",
       "  2321,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  4966,\n",
       "  1011,\n",
       "  10507,\n",
       "  2050,\n",
       "  2059,\n",
       "  12068,\n",
       "  2000,\n",
       "  1996,\n",
       "  2110,\n",
       "  4259,\n",
       "  2457,\n",
       "  1012,\n",
       "  102,\n",
       "  1996,\n",
       "  4966,\n",
       "  10507,\n",
       "  2050,\n",
       "  12068,\n",
       "  2008,\n",
       "  3247,\n",
       "  2000,\n",
       "  1996,\n",
       "  1057,\n",
       "  1012,\n",
       "  1055,\n",
       "  1012,\n",
       "  4259,\n",
       "  2457,\n",
       "  1012,\n",
       "  102]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = tokenized_datasets[\"train\"][:8]\n",
    "samples['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e3726188",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "387fb384",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples\n",
    "temp = [len(x) for x in samples[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c56077bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c12c4490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ee7c4d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 67]),\n",
       " 'token_type_ids': torch.Size([8, 67]),\n",
       " 'attention_mask': torch.Size([8, 67]),\n",
       " 'labels': torch.Size([8])}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator(samples)\n",
    "\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3ca3d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b0ea60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
